{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUxlur371EFV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import style\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import random\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zfqt0Atw2xrO",
        "colab_type": "text"
      },
      "source": [
        "Problem 1\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vuyAqfDd1Maz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a57eb9c1-c824-42a4-c943-b4a98bdefe27"
      },
      "source": [
        "massDist = (0.2,0.4,0.1,0.1,0.1,0.1)\n",
        "\n",
        "np.random.seed(500)\n",
        "\n",
        "\n",
        "for i in range(250):\n",
        "    randomwalk = [0]\n",
        "    for x in range(100):\n",
        "        step = randomwalk[-1]\n",
        "        dice = np.random.randint(1,7)\n",
        "        if dice <= 2 :\n",
        "            step = max(0, step - 1)\n",
        "\n",
        "        elif dice<=5:\n",
        "            step += 1\n",
        "\n",
        "        else:\n",
        "            step = step + np.random.randint(1,7)\n",
        "        \n",
        "def roll(massDist):\n",
        "    randRoll = random.random() # in [0,1]\n",
        "    sum = 0\n",
        "    result = 1\n",
        "    for mass in massDist:\n",
        "        sum += mass\n",
        "        if randRoll < sum:\n",
        "            return result\n",
        "        result+=1\n",
        "\n",
        "def dice(massDict):\n",
        "  step = 0;\n",
        "  numstep = 0;\n",
        "  for i in range(100000):\n",
        "    for i in range(250):\n",
        "      result = roll(massDict)\n",
        "      # print(\"You rolled\",result)\n",
        "      if result==1 or result==2: step=max(0,step-1)\n",
        "      elif result>=3 and result<=5: step=step+1\n",
        "      else: \n",
        "        result1 = roll(massDict)\n",
        "        step=step+result1\n",
        "    if step>60: numstep=numstep+1\n",
        "  return numstep\n",
        "\n",
        "  \n",
        "numstep = dice(massDist)\n",
        "print(\"Probability = \",numstep/100000)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Probability =  0.2813\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJ71k7cm25WM",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Problem 2\n",
        "Random Data for multiple linear regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UcxX1zFI29up",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "a6387dc5-a921-4db0-9661-c456e709c63d"
      },
      "source": [
        "import scipy\n",
        "from scipy.stats import norm\n",
        "\n",
        "random.seed(1)\n",
        "n_features = 4\n",
        "X = []\n",
        "for i in range(n_features):\n",
        "  X_i = scipy.stats.norm.rvs(0, 1, 100)\n",
        "  X.append(X_i)\n",
        "eps = scipy.stats.norm.rvs(0, 0.25,100)\n",
        "y = 1 + (0.4 * X[0]) + eps + (0.5 * X[1]) + (0.3 * X[2]) + (0.4 * X[3])\n",
        "data_mlr = {'X0': X[0],'X1':X[1],'X2':X[2],'X3':X[3],'Y': y }\n",
        "df = pd.DataFrame(data_mlr)\n",
        "print(df.head())\n",
        "print(df.tail())\n",
        "# print(df.info())\n",
        "# print(df.describe())"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         X0        X1        X2        X3         Y\n",
            "0  1.874943  0.496092 -0.545200  2.095419  2.065371\n",
            "1  0.900675 -0.016968  0.579549 -0.641197  1.415281\n",
            "2 -0.729338  0.823654  1.103555  2.080206  1.506872\n",
            "3 -0.273685  1.909639  0.168191  0.725733  1.926309\n",
            "4 -0.130937 -1.109134  1.166501 -0.088687  0.605078\n",
            "          X0        X1        X2        X3         Y\n",
            "95  0.511073  1.315345  0.708527  1.055346  1.935342\n",
            "96 -0.920894 -1.188387 -0.128048  1.138610  0.795669\n",
            "97 -2.233948  0.375408 -0.939577 -0.351305 -0.111779\n",
            "98  0.456095 -0.124628 -0.181742  0.050254  0.909499\n",
            "99  1.401999  0.343681 -1.231137 -1.914464  0.358183\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_Qkxtvl3Nyc",
        "colab_type": "text"
      },
      "source": [
        "Random Data for Logistic Regression\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYYfhSVH3Cdq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        },
        "outputId": "a0a63e57-2da8-4ece-e9c6-c400603e71cc"
      },
      "source": [
        "n_features = 4\n",
        "X = []\n",
        "for i in range(n_features):\n",
        "  X_i = scipy.stats.norm.rvs(0, 1, 100)\n",
        "  X.append(X_i)\n",
        "#print(X)\n",
        "a1 = (np.exp(1 + (0.5 * X[0]) + (0.4 * X[1]) + (0.3 * X[2]) + (0.5 * X[3]))/(1 + np.exp(1 + (0.5 * X[0]) + (0.4 * X[1]) + (0.3 * X[2]) + (0.5 * X[3]))))\n",
        "#print(a1)\n",
        "y1 = []\n",
        "for i in a1:\n",
        "  if (i>=0.5):\n",
        "    y1.append(1)\n",
        "  else:\n",
        "    y1.append(0)\n",
        "#print(y1)\n",
        "data_lr = {'X0': X[0],'X1':X[1],'X2':X[2],'X3':X[3],'Y': y1 }\n",
        "df1 = pd.DataFrame(data_lr)\n",
        "print(df1.head())\n",
        "print(df1.tail())\n",
        "# print(df1.info())\n",
        "# print(df1.describe())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "         X0        X1        X2        X3  Y\n",
            "0  0.557380  0.741905  0.777514 -1.273779  1\n",
            "1  0.156801 -0.742347 -0.220472  0.517015  1\n",
            "2  1.556367  0.661052  1.313165  1.755087  1\n",
            "3 -1.205235 -0.521159  0.140533  0.593147  1\n",
            "4  0.939161  0.356237  2.002919 -0.774120  1\n",
            "          X0        X1        X2        X3  Y\n",
            "95 -0.427232 -0.263579  0.257241  0.654363  1\n",
            "96  0.153881 -0.063387 -0.131813 -1.573812  1\n",
            "97  0.754534  0.103501  0.630714 -1.501059  1\n",
            "98 -0.012288 -0.000023  1.553754 -0.826928  1\n",
            "99 -0.187867  0.806092  1.841521 -0.476046  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DioO30c23e9m",
        "colab_type": "text"
      },
      "source": [
        "Random Data for K means clustering\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fc_PQmb93ZHu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        },
        "outputId": "758606de-ac15-48ae-e448-48973f88c0af"
      },
      "source": [
        "X_a= -2 * np.random.rand(100,2)\n",
        "X_b = 1 + 2 * np.random.rand(50,2)\n",
        "X_a[50:100, :] = X_b\n",
        "plt.scatter(X_a[ : , 0], X_a[ :, 1], s = 50)\n",
        "plt.show()\n",
        "data_kmean = {'X0': X_a[:,0],'X1':X_a[:,1]}\n",
        "df3 = pd.DataFrame(data_kmean)\n",
        "print(df3.head())\n",
        "print(df3.tail())\n",
        "# print(df3.info())\n",
        "# print(df3.describe())"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "         X0        X1\n",
            "0 -1.345324 -0.937370\n",
            "1 -0.504131 -0.854932\n",
            "2 -0.040176 -0.092736\n",
            "3 -1.634428 -1.988677\n",
            "4 -1.758289 -1.023820\n",
            "          X0        X1\n",
            "95  1.220136  1.569924\n",
            "96  2.804706  2.932117\n",
            "97  1.962695  2.551219\n",
            "98  1.272840  2.430041\n",
            "99  1.480684  1.943552\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "haYoVPej3tKV",
        "colab_type": "text"
      },
      "source": [
        "Problem Statement 3\n",
        "Linear Regression using gradient descent"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "541JEKLJ3vci",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1a97b828-64ea-4d1f-d752-6a71bbc5bf63"
      },
      "source": [
        "X = df.iloc[:,0].values\n",
        "y = df.iloc[:,4].values\n",
        "b1 = 0\n",
        "b0 = 0\n",
        "l = 0.001\n",
        "epochs = 100\n",
        " \n",
        "n = float(len(X))\n",
        "for i in range(epochs):\n",
        "  y_p = b1*X + b0\n",
        "  loss = np.sum(y_p - y1)**2\n",
        "  d1 = (-2/n) * sum(X * (y - y_p))\n",
        "  d0 = (-2/n) * sum(y - y_p)\n",
        "  b1 = b1 - (l*d1)\n",
        "  b0 = b0 - (l*d0)\n",
        "\n",
        "print(b1,b0)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.06311472246687973 0.1929052307350068\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPsia2cV32nG",
        "colab_type": "text"
      },
      "source": [
        "Logistic regression using gradient descent\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GNPaNsE43yJB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "ec9ceff3-d92a-469c-fc8b-37e91582f086"
      },
      "source": [
        "X1 = df1.iloc[:,0:4].values\n",
        "y1 = df1.iloc[:,4].values\n",
        "\n",
        "def sigmoid(Z):\n",
        "  return 1 /(1+np.exp(-Z))\n",
        "\n",
        "def loss(y1,y_hat):\n",
        "  return -np.mean(y1*np.log(y_hat) + (1-y1)*(np.log(1-y_hat)))\n",
        "\n",
        "W = np.zeros((4,1))\n",
        "b = np.zeros((1,1))\n",
        "\n",
        "m = len(y1)\n",
        "lr = 0.001\n",
        "for epoch in range(1000):\n",
        "  Z = np.matmul(X1,W)+b\n",
        "  A = sigmoid(Z)\n",
        "  logistic_loss = loss(y1,A)\n",
        "  dz = A - y1\n",
        "  dw = 1/m * np.matmul(X1.T,dz)\n",
        "  db = np.sum(dz)\n",
        "\n",
        "  W = W - lr*dw\n",
        "  b = b - lr*db\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print(logistic_loss)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6931471805599453\n",
            "0.32482613231849466\n",
            "0.32457316693200217\n",
            "0.3243240386888269\n",
            "0.32407871007097117\n",
            "0.3238371439830191\n",
            "0.32359930370592843\n",
            "0.32336515285303546\n",
            "0.32313465532830704\n",
            "0.3229077752868605\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNQs1Q0d3_w2",
        "colab_type": "text"
      },
      "source": [
        "Linear regression using L1 regularization\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qf1xpE4037CR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7b399a31-f3f2-4199-aa4d-acb50bb1abde"
      },
      "source": [
        "X = df.iloc[:,0].values\n",
        "y = df.iloc[:,4].values\n",
        "b1 = 0\n",
        "b0 = 0\n",
        "l = 0.001\n",
        "epochs = 100\n",
        "lam = 0.1\n",
        " \n",
        "n = float(len(X))\n",
        "for i in range(epochs):\n",
        "  y_p = b1*X + b0\n",
        "  loss = np.sum(y_p - y1)**2 + (lam * b1)\n",
        "  d1 = (-2/n) * sum(X * (y - y_p)) + lam\n",
        "  d0 = (-2/n) * sum(y - y_p)\n",
        "  b1 = b1 - (l*d1)\n",
        "  b0 = b0 - (l*d0)\n",
        "\n",
        "print(b1,b0)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.05397149288021046 0.1928958786280443\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ivdltd2M4ENr",
        "colab_type": "text"
      },
      "source": [
        "Linear Regression using L2 regularization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SILCuwP94DsF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ea2c9c2a-c54d-4b06-8de3-72156a818ad0"
      },
      "source": [
        "X = df.iloc[:,0].values\n",
        "y = df.iloc[:,4].values\n",
        "b1 = 0\n",
        "b0 = 0\n",
        "l = 0.001\n",
        "epochs = 100\n",
        "lam = 0.1\n",
        " \n",
        "n = float(len(X))\n",
        "for i in range(epochs):\n",
        "  y_p = b1*X + b0\n",
        "  loss = np.sum(y_p - y1)**2 + ((lam/2) * b1)\n",
        "  d1 = (-2/n) * sum(X * (y - y_p)) + (lam *b1)\n",
        "  d0 = (-2/n) * sum(y - y_p)\n",
        "  b1 = b1 - (l*d1)\n",
        "  b0 = b0 - (l*d0)\n",
        "\n",
        "print(b1,b0)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.06281269543743173 0.1929050233186898\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V97R3Cns4K4t",
        "colab_type": "text"
      },
      "source": [
        "Logistic regression using L1 regularization\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzMur1LV4O30",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "6bf3e874-7319-4ad8-ad8e-82e067b2cb36"
      },
      "source": [
        "X1 = df1.iloc[:,0:4].values\n",
        "y1 = df1.iloc[:,4].values\n",
        "lam = 0.1\n",
        "def sigmoid(Z):\n",
        "  return 1 /(1+np.exp(-Z))\n",
        "\n",
        "def loss(y1,y_hat):\n",
        "  return -np.mean(y1*np.log(y_hat) + (1-y1)*(np.log(1-y_hat))) + (lam * (np.sum(W)))\n",
        "\n",
        "W = np.zeros((4,1))\n",
        "b = np.zeros((1,1))\n",
        "\n",
        "m = len(y1)\n",
        "lr = 0.001\n",
        "for epoch in range(1000):\n",
        "  Z = np.matmul(X1,W)+b\n",
        "  A = sigmoid(Z)\n",
        "  logistic_loss = loss(y1,A)\n",
        "  dz = A - y1\n",
        "  dw = 1/m * np.matmul(X1.T,dz) + lam\n",
        "  db = np.sum(dz)\n",
        "\n",
        "  W = W - lr*dw\n",
        "  b = b - lr*db\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print(logistic_loss)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6931471805599453\n",
            "-0.07271550151373607\n",
            "-0.4661448385480806\n",
            "-0.8550594293110557\n",
            "-1.239505404282359\n",
            "-1.6195299699660086\n",
            "-1.9951813168021264\n",
            "-2.366508529343363\n",
            "-2.7335614988041868\n",
            "-3.096390838066413\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJ651dOj5oox",
        "colab_type": "text"
      },
      "source": [
        "Logistic regression using L2 regularization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AITF2E64SH7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        },
        "outputId": "1fe93ff0-ace1-49e7-ac82-12f20d92a0c7"
      },
      "source": [
        "X1 = df1.iloc[:,0:4].values\n",
        "y1 = df1.iloc[:,4].values\n",
        "lam = 0.1\n",
        "def sigmoid(Z):\n",
        "  return 1 /(1+np.exp(-Z))\n",
        "\n",
        "def loss(y1,y_hat):\n",
        "  return -np.mean(y1*np.log(y_hat) + (1-y1)*(np.log(1-y_hat))) + (lam * (np.sum(np.square(W))))\n",
        "\n",
        "W = np.zeros((4,1))\n",
        "b = np.zeros((1,1))\n",
        "\n",
        "m = len(y1)\n",
        "lr = 0.001\n",
        "for epoch in range(1000):\n",
        "  Z = np.matmul(X1,W)+b\n",
        "  A = sigmoid(Z)\n",
        "  logistic_loss = loss(y1,A)\n",
        "  dz = A - y1\n",
        "  dw = 1/m * np.matmul(X1.T,dz) + lam * W\n",
        "  db = np.sum(dz)\n",
        "\n",
        "  W = W - lr*dw\n",
        "  b = b - lr*db\n",
        "\n",
        "  if epoch % 100 == 0:\n",
        "    print(logistic_loss)"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.6931471805599453\n",
            "0.3250817316142215\n",
            "0.32557779341894805\n",
            "0.32654525267264584\n",
            "0.32795916239591844\n",
            "0.32979551626056636\n",
            "0.33203121795193047\n",
            "0.33464405165503625\n",
            "0.3376126535983076\n",
            "0.3409164845933777\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSQcdoZW5hPc",
        "colab_type": "text"
      },
      "source": [
        "K means clustering\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwQ5Pszv4Xsy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "outputId": "8faaa453-1fcb-4ae0-950a-e09a6632d1e5"
      },
      "source": [
        "class K_Means:\n",
        "    def __init__(self, k=2, tol=0.001, max_iter=300):\n",
        "        self.k = k\n",
        "        self.tol = tol\n",
        "        self.max_iter = max_iter\n",
        "\n",
        "    def fit(self,data):\n",
        "\n",
        "        self.centroids = {}\n",
        "\n",
        "        for i in range(self.k):\n",
        "            self.centroids[i] = data[i]\n",
        "\n",
        "        for i in range(self.max_iter):\n",
        "            self.classifications = {}\n",
        "\n",
        "            for i in range(self.k):\n",
        "                self.classifications[i] = []\n",
        "\n",
        "            for featureset in X:\n",
        "                distances = [np.linalg.norm(featureset-self.centroids[centroid]) for centroid in self.centroids]\n",
        "                classification = distances.index(min(distances))\n",
        "                self.classifications[classification].append(featureset)\n",
        "\n",
        "            prev_centroids = dict(self.centroids)\n",
        "\n",
        "            for classification in self.classifications:\n",
        "                self.centroids[classification] = np.average(self.classifications[classification],axis=0)\n",
        "\n",
        "            optimized = True\n",
        "\n",
        "            for c in self.centroids:\n",
        "                original_centroid = prev_centroids[c]\n",
        "                current_centroid = self.centroids[c]\n",
        "                if np.sum((current_centroid-original_centroid)/original_centroid*100.0) > self.tol:\n",
        "                    print(np.sum((current_centroid-original_centroid)/original_centroid*100.0))\n",
        "                    optimized = False\n",
        "\n",
        "            if optimized:\n",
        "                break\n",
        "\n",
        "    def predict(self,data):\n",
        "        distances = [np.linalg.norm(data-self.centroids[centroid]) for centroid in self.centroids]\n",
        "        classification = distances.index(min(distances))\n",
        "        return classification\n",
        "        \n",
        "colors = 10*[\"g\",\"r\",\"c\",\"b\",\"k\"]\n",
        "X = df3.iloc[:,0:2].values\n",
        "clf = K_Means()\n",
        "clf.fit(X)\n",
        "\n",
        "for centroid in clf.centroids:\n",
        "    plt.scatter(clf.centroids[centroid][0], clf.centroids[centroid][1],\n",
        "                marker=\"o\", color=\"k\", s=150, linewidths=5)\n",
        "\n",
        "for classification in clf.classifications:\n",
        "    color = colors[classification]\n",
        "    for featureset in clf.classifications[classification]:\n",
        "        plt.scatter(featureset[0], featureset[1], marker=\".\", color=color, s=150, linewidths=5)"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "13.455330315994415\n",
            "147.05874591196107\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZRlyfOe85dM0",
        "colab_type": "text"
      },
      "source": [
        "Problem Statement 4 \n",
        "\n",
        "Linear regression from scratch using oops"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2ZiXEqw4dCB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "class LinearRegressionModel():\n",
        "\n",
        "    def __init__(self, dataset, learning_rate, num_iterations):\n",
        "        self.dataset = np.array(dataset)\n",
        "        self.b = 0  \n",
        "        self.m = 0  \n",
        "        self.learning_rate = learning_rate\n",
        "        self.num_iterations = num_iterations\n",
        "        self.M = len(self.dataset)\n",
        "        self.total_error = 0\n",
        "\n",
        "    def apply_gradient_descent(self):\n",
        "        for i in range(self.num_iterations):\n",
        "            self.do_gradient_step()\n",
        "\n",
        "    def do_gradient_step(self):\n",
        "        b_summation = 0\n",
        "        m_summation = 0\n",
        "        for i in range(self.M):\n",
        "            x_value = self.dataset[i, 0]\n",
        "            y_value = self.dataset[i, 1]\n",
        "            b_summation += (((self.m * x_value) + self.b) - y_value) \n",
        "            m_summation += (((self.m * x_value) + self.b) - y_value) * x_value\n",
        "        self.b = self.b - (self.learning_rate * (1/self.M) * b_summation)\n",
        "        self.m = self.m - (self.learning_rate * (1/self.M) * m_summation)\n",
        "      \n",
        "    def compute_error(self):\n",
        "        for i in range(self.M):\n",
        "            x_value = self.dataset[i, 0]\n",
        "            y_value = self.dataset[i, 1]\n",
        "            self.total_error += ((self.m * x_value) + self.b) - y_value\n",
        "        return self.total_error\n",
        "\n",
        "    def __str__(self):\n",
        "        return \"Results: b: {}, m: {}, Final Total error: {}\".format(round(self.b, 2), round(self.m, 2), round(self.compute_error(), 2))\n",
        "\n",
        "    def get_prediction_based_on(self, x):\n",
        "        return round(float((self.m * x) + self.b), 2) # Type: Numpy float.\n",
        "\n",
        "def main():\n",
        "    school_dataset = np.genfromtxt(DATASET_PATH, delimiter=\",\")\n",
        "    lr = LinearRegressionModel(school_dataset, 0.0001, 1000)\n",
        "    lr.apply_gradient_descent()\n",
        "    hours = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100]\n",
        "    for hour in hours:\n",
        "        print(\"Studied {} hours and got {} points.\".format(hour, lr.get_prediction_based_on(hour)))\n",
        "    print(lr)\n",
        "\n",
        "if __name__ == \"__main__\": main()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uxo0JgHW5aZY",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Logistic regression from scratch using oops"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LS2eTBF65Gqk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LogisticRegression:\n",
        "  def __init__(self, learning_rate, num_iters, fit_intercept = True, verbose = False):\n",
        "    self.learning_rate = learning_rate\n",
        "    self.num_iters = num_iters\n",
        "    self.fit_intercept = fit_intercept\n",
        "    self.verbose = verbose\n",
        "  def __add_intercept(self, X):\n",
        "    intercept = np.ones((X.shape[0],1))\n",
        "    return np.concatenate((intercept,X),axis=1)\n",
        "  def __sigmoid(self,z):\n",
        "    return 1/(1+np.exp(-z))\n",
        "  def __loss(self, h, y):\n",
        "    return (-y * np.log(h) - (1-y) * np.log(1-h)).mean()\n",
        "  \n",
        "  def fit(self,X,y):\n",
        "    if self.fit_intercept:\n",
        "      X = self.__add_intercept(X)\n",
        "    self.theta = np.zeros(X.shape[1])\n",
        "    \n",
        "    for i in range(self.num_iters):\n",
        "      z = np.dot(X,self.theta)\n",
        "      h = self.__sigmoid(z)\n",
        "      gradient = np.dot(X.T,(h-y))/y.size\n",
        "      \n",
        "      self.theta -= self.learning_rate * gradient\n",
        "      \n",
        "      z = np.dot(X,self.theta)\n",
        "      h = self.__sigmoid(z)\n",
        "      loss = self.__loss(h,y)\n",
        "      \n",
        "      if self.verbose == True and i % 1000 == 0:\n",
        "        print(f'Loss: {loss}\\t')\n",
        "  def predict_probability(self,X):\n",
        "    if self.fit_intercept:\n",
        "      X = self.__add_intercept(X)\n",
        "    return self.__sigmoid(np.dot(X,self.theta))\n",
        "  def predict(self,X):\n",
        "    return (self.predict_probability(X).round())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5QCvA9_5PNW",
        "colab_type": "text"
      },
      "source": [
        "K means clustering from scratch using oops\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68Aj92Bw5Nuw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class K_Means:\n",
        "    def __init__(self, k=2, tol=0.001, max_iter=300):\n",
        "        self.k = k\n",
        "        self.tol = tol\n",
        "        self.max_iter = max_iter\n",
        "\n",
        "    def fit(self,data):\n",
        "\n",
        "        self.centroids = {}\n",
        "\n",
        "        for i in range(self.k):\n",
        "            self.centroids[i] = data[i]\n",
        "\n",
        "        for i in range(self.max_iter):\n",
        "            self.classifications = {}\n",
        "\n",
        "            for i in range(self.k):\n",
        "                self.classifications[i] = []\n",
        "\n",
        "            for featureset in X:\n",
        "                distances = [np.linalg.norm(featureset-self.centroids[centroid]) for centroid in self.centroids]\n",
        "                classification = distances.index(min(distances))\n",
        "                self.classifications[classification].append(featureset)\n",
        "\n",
        "            prev_centroids = dict(self.centroids)\n",
        "\n",
        "            for classification in self.classifications:\n",
        "                self.centroids[classification] = np.average(self.classifications[classification],axis=0)\n",
        "\n",
        "            optimized = True\n",
        "\n",
        "            for c in self.centroids:\n",
        "                original_centroid = prev_centroids[c]\n",
        "                current_centroid = self.centroids[c]\n",
        "                if np.sum((current_centroid-original_centroid)/original_centroid*100.0) > self.tol:\n",
        "                    print(np.sum((current_centroid-original_centroid)/original_centroid*100.0))\n",
        "                    optimized = False\n",
        "\n",
        "            if optimized:\n",
        "                break\n",
        "\n",
        "    def predict(self,data):\n",
        "        distances = [np.linalg.norm(data-self.centroids[centroid]) for centroid in self.centroids]\n",
        "        classification = distances.index(min(distances))\n",
        "        return classification\n",
        "        \n",
        "colors = 10*[\"g\",\"r\",\"c\",\"b\",\"k\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B3aXiZil57kI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}